{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c13dc825-c724-428e-a949-9afb82f84a47",
   "metadata": {},
   "source": [
    "# Training a classifier with gaze features for calculating predictions of various activities\n",
    "\n",
    "__UbiComp Assignment 02, Task 01:__\n",
    "This third notebook trains a classifier with select features and corresponding labels.\\\n",
    "The features and labels are read from a given csv-file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9fc75e-d0d9-4adc-b9c8-19799bb714af",
   "metadata": {},
   "source": [
    "## Read data from a csv-file.\n",
    "\n",
    "Note that the csv-file we are using here is generated by the FeatureCalculation Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "717202ba-c9c8-4fef-b370-47f3d431c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "recording_location = './'\n",
    "\n",
    "all_features_csv = os.path.join(recording_location, './Data/FeatureFiles/feature_list_all.csv')\n",
    "df = pd.read_csv(all_features_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f558ba8-ddf7-45d6-a3f9-9a807728215f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of the CSV file are 19 features, label of the activity, duration or the timespan of the activity, and the ID of the participant:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['meanFix',\n",
       " 'minFix',\n",
       " 'maxFix',\n",
       " 'varFix',\n",
       " 'stdFix',\n",
       " 'meanDis',\n",
       " 'minDis',\n",
       " 'maxDis',\n",
       " 'varDis',\n",
       " 'stdDisp',\n",
       " 'freqDisPerSec',\n",
       " 'number_of_blinks',\n",
       " 'blinkMean',\n",
       " 'blinkMin',\n",
       " 'blinkMax',\n",
       " 'blinkRate',\n",
       " 'xDir',\n",
       " 'yDir',\n",
       " 'fixDensPerBB',\n",
       " 'label',\n",
       " 'duration',\n",
       " 'participant_id']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines to see all columns of the csv file (i.e., the features and labels)\n",
    "print(\"Columns of the CSV file are 19 features, label of the activity, duration or the timespan of the activity, and the ID of the participant:\")\n",
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6967ae7-6306-4c05-aab5-08523019c483",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "read_df = df[df.label == 'Reading']\n",
    "inspect_df = df[df.label == 'Inspection']\n",
    "search_df = df[df.label == 'Search']\n",
    "\n",
    "#print(\"Sample reading data:\")\n",
    "#display(read_df[['meanFix', 'maxFix', 'varFix', 'xDir', 'yDir']].head(10))\n",
    "\n",
    "#print(\"Sample inspection data:\")\n",
    "#display(inspect_df[['meanFix', 'maxFix', 'varFix', 'xDir', 'yDir']].head(10))\n",
    "\n",
    "#print(\"Sample search data:\")\n",
    "#display(search_df[['meanFix', 'maxFix', 'varFix', 'xDir', 'yDir']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef7bbfe-8c34-479e-8c57-3468c902f66d",
   "metadata": {},
   "source": [
    "## For the classification we used a modified version of [an SVM cassifier.](https://towardsdatascience.com/multiclass-classification-with-support-vector-machines-svm-kernel-trick-kernel-functions-f9d5377d6f02)\n",
    "First, we need to include some libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fec7f70-4561-45ad-b39c-a258e8cc6658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#Importing the necessary packages and libaries\n",
    "#\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feddf5c9-1311-4c7c-ba92-c97f6520b5d7",
   "metadata": {},
   "source": [
    "## Let's store the labels and six selected features (among nineteen as denoted in the csv file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8043316-b7d3-4cda-a12e-2af68ebe52c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[[\"meanFix\", \"maxFix\", \"varFix\", \"xDir\", \"yDir\", \"fixDensPerBB\"]]\n",
    "labels = df ['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb698ed1-b3f7-40b4-b9a7-b9d4f5e15586",
   "metadata": {},
   "source": [
    "## This is how the features and labels look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b2f2735-873c-46ed-8fc3-5dd1cd24c32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanFix</th>\n",
       "      <th>maxFix</th>\n",
       "      <th>varFix</th>\n",
       "      <th>xDir</th>\n",
       "      <th>yDir</th>\n",
       "      <th>fixDensPerBB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250.882353</td>\n",
       "      <td>666</td>\n",
       "      <td>16554.228164</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>369.479986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>246.742857</td>\n",
       "      <td>900</td>\n",
       "      <td>23549.020168</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>363.711018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>237.257143</td>\n",
       "      <td>1067</td>\n",
       "      <td>36627.431933</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>266.246748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>293.137931</td>\n",
       "      <td>767</td>\n",
       "      <td>35208.551724</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>319.553727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199.125000</td>\n",
       "      <td>566</td>\n",
       "      <td>12614.163462</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>305.832090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>262.562500</td>\n",
       "      <td>867</td>\n",
       "      <td>36411.415323</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>236.757891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>204.175000</td>\n",
       "      <td>733</td>\n",
       "      <td>16987.430128</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>445.453567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>221.540541</td>\n",
       "      <td>733</td>\n",
       "      <td>19568.977477</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>538.273012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>430.095238</td>\n",
       "      <td>2567</td>\n",
       "      <td>322794.690476</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>77.460002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>227.805556</td>\n",
       "      <td>533</td>\n",
       "      <td>8651.246825</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>132.320562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      meanFix  maxFix         varFix      xDir      yDir  fixDensPerBB\n",
       "0  250.882353     666   16554.228164  0.484848  0.606061    369.479986\n",
       "1  246.742857     900   23549.020168  0.529412  0.529412    363.711018\n",
       "2  237.257143    1067   36627.431933  0.441176  0.558824    266.246748\n",
       "3  293.137931     767   35208.551724  0.500000  0.500000    319.553727\n",
       "4  199.125000     566   12614.163462  0.589744  0.487179    305.832090\n",
       "5  262.562500     867   36411.415323  0.516129  0.580645    236.757891\n",
       "6  204.175000     733   16987.430128  0.538462  0.512821    445.453567\n",
       "7  221.540541     733   19568.977477  0.583333  0.500000    538.273012\n",
       "8  430.095238    2567  322794.690476  0.800000  0.450000     77.460002\n",
       "9  227.805556     533    8651.246825  0.914286  0.457143    132.320562"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Inspection\n",
       "1    Inspection\n",
       "2    Inspection\n",
       "3    Inspection\n",
       "4    Inspection\n",
       "5    Inspection\n",
       "6    Inspection\n",
       "7    Inspection\n",
       "8       Reading\n",
       "9       Reading\n",
       "Name: label, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Features:\")\n",
    "display(features.head(10))\n",
    "print(\"Labels:\")\n",
    "display(labels.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da3bed1-a124-4403-b013-648ac2d11eba",
   "metadata": {},
   "source": [
    "## Let's normalize the features (i.e., each column indivudally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99609c76-2a2c-4432-be59-681ca370b3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanFix</th>\n",
       "      <th>maxFix</th>\n",
       "      <th>varFix</th>\n",
       "      <th>xDir</th>\n",
       "      <th>yDir</th>\n",
       "      <th>fixDensPerBB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.412048</td>\n",
       "      <td>0.144783</td>\n",
       "      <td>0.013814</td>\n",
       "      <td>0.527009</td>\n",
       "      <td>0.743802</td>\n",
       "      <td>0.238355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.405249</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.019651</td>\n",
       "      <td>0.575448</td>\n",
       "      <td>0.649733</td>\n",
       "      <td>0.234633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.389670</td>\n",
       "      <td>0.231957</td>\n",
       "      <td>0.030564</td>\n",
       "      <td>0.479540</td>\n",
       "      <td>0.685829</td>\n",
       "      <td>0.171758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.481448</td>\n",
       "      <td>0.166739</td>\n",
       "      <td>0.029380</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.206147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.327042</td>\n",
       "      <td>0.123043</td>\n",
       "      <td>0.010526</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.597902</td>\n",
       "      <td>0.197295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.431232</td>\n",
       "      <td>0.188478</td>\n",
       "      <td>0.030384</td>\n",
       "      <td>0.561010</td>\n",
       "      <td>0.712610</td>\n",
       "      <td>0.152735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.335336</td>\n",
       "      <td>0.159348</td>\n",
       "      <td>0.014175</td>\n",
       "      <td>0.585284</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.287366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.363857</td>\n",
       "      <td>0.159348</td>\n",
       "      <td>0.016330</td>\n",
       "      <td>0.634058</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.347245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.706387</td>\n",
       "      <td>0.558043</td>\n",
       "      <td>0.269361</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.552273</td>\n",
       "      <td>0.049970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.374147</td>\n",
       "      <td>0.115870</td>\n",
       "      <td>0.007219</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>0.561039</td>\n",
       "      <td>0.085361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    meanFix    maxFix    varFix      xDir      yDir  fixDensPerBB\n",
       "0  0.412048  0.144783  0.013814  0.527009  0.743802      0.238355\n",
       "1  0.405249  0.195652  0.019651  0.575448  0.649733      0.234633\n",
       "2  0.389670  0.231957  0.030564  0.479540  0.685829      0.171758\n",
       "3  0.481448  0.166739  0.029380  0.543478  0.613636      0.206147\n",
       "4  0.327042  0.123043  0.010526  0.641026  0.597902      0.197295\n",
       "5  0.431232  0.188478  0.030384  0.561010  0.712610      0.152735\n",
       "6  0.335336  0.159348  0.014175  0.585284  0.629371      0.287366\n",
       "7  0.363857  0.159348  0.016330  0.634058  0.613636      0.347245\n",
       "8  0.706387  0.558043  0.269361  0.869565  0.552273      0.049970\n",
       "9  0.374147  0.115870  0.007219  0.993789  0.561039      0.085361"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(features)\n",
    "scaled = scaler.transform(features)\n",
    "scaled_features = pd.DataFrame(scaled, columns=features.columns)\n",
    "print(\"Normalized Features:\")\n",
    "display(scaled_features.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcc9ebb-cc4e-4f99-84e7-24ab7fc85dfe",
   "metadata": {},
   "source": [
    "## Let's split the data and have two sets, one for training the model and one for testing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "744f945f-8b52-4b11-a9b2-16efe1c5e5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train, feature_test, label_train, label_test = train_test_split(features, labels, train_size=0.8, random_state = 0, stratify=labels)\n",
    "\n",
    "# Uncomment the following line if you want to work with normalized features. You will note how the accuracy and confusion matrix changes\n",
    "# feature_train, feature_test, label_train, label_test = train_test_split(scaled_features, labels, train_size=0.8, random_state = 0, stratify=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0528fdfc-2f06-4576-a303-45e37953e817",
   "metadata": {},
   "source": [
    "## We can work with different SVM-kernels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63ceef7e-6355-4a91-9d04-81fb9f976a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo', probability=True).fit(feature_train, label_train)\n",
    "\n",
    "rbf = svm.SVC(kernel='rbf', gamma=1, C=1, decision_function_shape='ovo', probability=True).fit(feature_train, label_train)\n",
    "\n",
    "poly = svm.SVC(kernel='poly', degree=3, C=1, decision_function_shape='ovo', probability=True).fit(feature_train, label_train)\n",
    "\n",
    "sig = svm.SVC(kernel='sigmoid', C=1, decision_function_shape='ovo', probability=True).fit(feature_train, label_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216dce42-a816-478c-b277-57f91a3e6565",
   "metadata": {},
   "source": [
    "## Lets collect the predictions from test data. . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73c40d20-1299-4210-b1ea-bfa2bdea8ddb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linear' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Lukas Volk\\Documents\\Playground\\UbiComp\\python\\AnSVMClassifierForHL2GazeFeatures.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Lukas%20Volk/Documents/Playground/UbiComp/python/AnSVMClassifierForHL2GazeFeatures.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m linear_pred \u001b[39m=\u001b[39m linear\u001b[39m.\u001b[39mpredict(feature_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lukas%20Volk/Documents/Playground/UbiComp/python/AnSVMClassifierForHL2GazeFeatures.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m poly_pred \u001b[39m=\u001b[39m poly\u001b[39m.\u001b[39mpredict(feature_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lukas%20Volk/Documents/Playground/UbiComp/python/AnSVMClassifierForHL2GazeFeatures.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m rbf_pred \u001b[39m=\u001b[39m rbf\u001b[39m.\u001b[39mpredict(feature_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'linear' is not defined"
     ]
    }
   ],
   "source": [
    "linear_pred = linear.predict(feature_test)\n",
    "poly_pred = poly.predict(feature_test)\n",
    "rbf_pred = rbf.predict(feature_test)\n",
    "sig_pred = sig.predict(feature_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c6e6e2-98ea-460e-845e-89ccc73a2dc0",
   "metadata": {},
   "source": [
    "## . . . and have a look at the accuracy of each one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495965c2-a129-40d0-a94b-449f1758150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the accuracy and print it for all 4 kernel functions\n",
    "accuracy_lin = linear.score(feature_test, label_test)\n",
    "accuracy_poly = poly.score(feature_test, label_test)\n",
    "accuracy_rbf = rbf.score(feature_test, label_test)\n",
    "accuracy_sig = sig.score(feature_test, label_test)\n",
    "\n",
    "print(\"Accuracy Linear Kernel:\", accuracy_lin)\n",
    "print(\"Accuracy Polynomial Kernel:\", accuracy_poly)\n",
    "print(\"Accuracy Radial Basis Kernel:\", accuracy_rbf)\n",
    "print(\"Accuracy Sigmoid Kernel:\", accuracy_sig)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b05e747-3635-4148-bd0e-a5a6aaa891d3",
   "metadata": {},
   "source": [
    "## This is how the confusion matrix of each predictor looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74deeabf-74c9-45e2-9b32-95af9d92561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a confusion matrix\n",
    "cm_lin = confusion_matrix(label_test, linear_pred)\n",
    "cm_poly = confusion_matrix(label_test, poly_pred)\n",
    "cm_rbf = confusion_matrix(label_test, rbf_pred)\n",
    "cm_sig = confusion_matrix(label_test, sig_pred)\n",
    "\n",
    "print(\"CM Linear:\")\n",
    "print(cm_lin)\n",
    "print(\"CM Polynomial:\")\n",
    "print(cm_poly)\n",
    "print(\"CM Radial:\")\n",
    "print(cm_rbf)\n",
    "print(\"CM Sigmoid:\")\n",
    "print(cm_sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9905bbea-de94-48ec-8f3f-c2a6d8680457",
   "metadata": {},
   "source": [
    "## A more colorful confusion matrix for the linear predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b432d298-2985-46bf-a147-34ccdfcad48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(linear, feature_test, label_test)\n",
    "ConfusionMatrixDisplay.from_estimator(poly, feature_test, label_test)\n",
    "ConfusionMatrixDisplay.from_estimator(rbf, feature_test, label_test)\n",
    "ConfusionMatrixDisplay.from_estimator(sig, feature_test, label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627a7624-ca06-4c7f-a416-f1a635bbc4e2",
   "metadata": {},
   "source": [
    "## Finally, let's make a cross check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de85dec9-ee74-43fc-b7e7-f94199f29764",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9270523e-4689-4f6d-bf4f-8a05e5cf3194",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.predict(np.array(features.iloc[59]).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6c570a-65ee-4326-bf0e-c79990d6ca07",
   "metadata": {},
   "source": [
    "## Let's detect the label (i.e., the activity) of some new features (i.e., that are extracted from a new stream of eye tracking data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c9a0e0-07de-41f2-b558-5995862350e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"New Feature:\")\n",
    "# NOTE that we use a particular feature from the test dataset but this can be replaced with new data e.g., that arrives online and was not included in training or testing the classifier\n",
    "new_feature = feature_test.tail(2)\n",
    "display(new_feature)\n",
    "\n",
    "new_linear_pred = linear.predict_proba(new_feature)\n",
    "new_linear_pred_2 = linear.predict(new_feature)\n",
    "print(\"New Linear Prediction:\")\n",
    "display(new_linear_pred)\n",
    "display(new_linear_pred_2)\n",
    "\n",
    "new_poly_pred_2 = poly.predict(new_feature)\n",
    "new_poly_pred = poly.predict_proba(new_feature)\n",
    "print(\"New Poly Prediction:\")\n",
    "display(new_poly_pred)\n",
    "display(new_poly_pred_2)\n",
    "\n",
    "new_rbf_pred_2 = rbf.predict(new_feature)\n",
    "new_rbf_pred = rbf.predict_proba(new_feature)\n",
    "print(\"New RBF Prediction:\")\n",
    "display(new_rbf_pred)\n",
    "display(new_rbf_pred_2)\n",
    "\n",
    "new_sig_pred_2 = sig.predict(new_feature)\n",
    "new_sig_pred = sig.predict_proba(new_feature)\n",
    "print(\"New Sig Prediction:\")\n",
    "display(new_sig_pred)\n",
    "display(new_sig_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78609658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267    Inspection\n",
       "352       Reading\n",
       "373       Reading\n",
       "297       Reading\n",
       "93     Inspection\n",
       "          ...    \n",
       "231       Reading\n",
       "336       Reading\n",
       "246    Inspection\n",
       "273       Reading\n",
       "28        Reading\n",
       "Name: label, Length: 308, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d269819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "443de76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"Inspection\", \"Reading\", \"Search\"]\n",
    "labels = [(classes.index(item)) for item in label_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6491d293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Inspection\n",
       "1      Inspection\n",
       "2      Inspection\n",
       "3      Inspection\n",
       "4      Inspection\n",
       "          ...    \n",
       "380        Search\n",
       "381        Search\n",
       "382        Search\n",
       "383        Search\n",
       "384        Search\n",
       "Name: label, Length: 385, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484bfbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81547a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with feature set: ['xDir', 'yDir', 'fixDensPerBB']\n",
      "Done with scaling: True\n",
      "{\"True, ['xDir', 'yDir', 'fixDensPerBB'], 10, 0.0005, -1, 1\": 0.8311688311688312, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 10, 0.0005, -1, 2\": 0.8311688311688312, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 10, 0.0005, -1, 3\": 0.8701298701298701, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 10, 0.005, -1, 1\": 0.8961038961038961, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 10, 0.005, -1, 2\": 0.8961038961038961, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 10, 0.005, -1, 3\": 0.8961038961038961, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 10, 0.05, -1, 1\": 0.8441558441558441, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 10, 0.05, -1, 2\": 0.8441558441558441, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 10, 0.05, -1, 3\": 0.8441558441558441, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 10, 0.5, -1, 1\": 0.8311688311688312, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 10, 0.5, -1, 2\": 0.8181818181818182, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 10, 0.5, -1, 3\": 0.8051948051948052, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 100, 0.0005, -1, 1\": 0.8311688311688312, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 100, 0.0005, -1, 2\": 0.8311688311688312, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 100, 0.0005, -1, 3\": 0.8701298701298701, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 100, 0.005, -1, 1\": 0.8961038961038961, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 100, 0.005, -1, 2\": 0.8961038961038961, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 100, 0.005, -1, 3\": 0.8961038961038961, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 100, 0.05, -1, 1\": 0.8441558441558441, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 100, 0.05, -1, 2\": 0.8441558441558441, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 100, 0.05, -1, 3\": 0.8441558441558441, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 100, 0.5, -1, 1\": 0.8311688311688312, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 100, 0.5, -1, 2\": 0.8181818181818182, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 100, 0.5, -1, 3\": 0.8051948051948052, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 1000, 0.0005, -1, 1\": 0.8311688311688312, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 1000, 0.0005, -1, 2\": 0.8311688311688312, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 1000, 0.0005, -1, 3\": 0.8701298701298701, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 1000, 0.005, -1, 1\": 0.8961038961038961, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 1000, 0.005, -1, 2\": 0.8961038961038961, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 1000, 0.005, -1, 3\": 0.8961038961038961, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 1000, 0.05, -1, 1\": 0.8441558441558441, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 1000, 0.05, -1, 2\": 0.8441558441558441, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 1000, 0.05, -1, 3\": 0.8441558441558441, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 1000, 0.5, -1, 1\": 0.8311688311688312, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 1000, 0.5, -1, 2\": 0.8181818181818182, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 1000, 0.5, -1, 3\": 0.8051948051948052, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 10000, 0.0005, -1, 1\": 0.8311688311688312, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 10000, 0.0005, -1, 2\": 0.8311688311688312, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 10000, 0.0005, -1, 3\": 0.8701298701298701, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 10000, 0.005, -1, 1\": 0.8961038961038961, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 10000, 0.005, -1, 2\": 0.8961038961038961, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 10000, 0.005, -1, 3\": 0.8961038961038961, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 10000, 0.05, -1, 1\": 0.8441558441558441, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 10000, 0.05, -1, 2\": 0.8441558441558441, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 10000, 0.05, -1, 3\": 0.8441558441558441, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 10000, 0.5, -1, 1\": 0.8311688311688312, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 10000, 0.5, -1, 2\": 0.8181818181818182, \"True, ['xDir', 'yDir', 'fixDensPerBB'], 10000, 0.5, -1, 3\": 0.8051948051948052}\n",
      "True, ['xDir', 'yDir', 'fixDensPerBB'], 10, 0.005, -1, 1: 0.8961038961038961\n",
      "True, ['xDir', 'yDir', 'fixDensPerBB'], 10, 0.005, -1, 2: 0.8961038961038961\n",
      "True, ['xDir', 'yDir', 'fixDensPerBB'], 10, 0.005, -1, 3: 0.8961038961038961\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "\n",
    "def setup_with_features(using_scaled_features = False, feature_set = ['participant_id']):\n",
    "    recording_location = './'\n",
    "\n",
    "    all_features_csv = os.path.join(recording_location, './Data/FeatureFiles/feature_list_all.csv')\n",
    "    df = pd.read_csv(all_features_csv)\n",
    "    features = df[feature_set]\n",
    "    labels = df ['label']\n",
    "    scaler = MaxAbsScaler()\n",
    "    scaler.fit(features)\n",
    "    scaled = scaler.transform(features)\n",
    "    scaled_features = pd.DataFrame(scaled, columns=features.columns)\n",
    "    if using_scaled_features:\n",
    "        feature_train, feature_test, label_train, label_test = train_test_split(scaled_features, labels, train_size=0.8, random_state = 0, stratify=labels)\n",
    "    else:\n",
    "        feature_train, feature_test, label_train, label_test = train_test_split(features, labels, train_size=0.8, random_state = 0, stratify=labels)\n",
    "    return feature_train, feature_test, label_train, label_test\n",
    "\n",
    "def test_parameters(results, using_scaling, f_set, feature_train, feature_test, label_train, label_test, iterations=1000, learning_rate=0.1, depth=6, l2_leaf_reg=3):\n",
    "    key = f'{str(using_scaling)}, {str(f_set)}, {str(iterations)}, {str(learning_rate)}, {str(depth)}, {str(l2_leaf_reg)}'\n",
    "    model = lgb.LGBMClassifier(\n",
    "        boosting_type='gbdt',\n",
    "        n_iterations=iterations,  # Number of boostinstr(l2_leaf_reg)g iterations\n",
    "        learning_rate=learning_rate,  # Learning rate\n",
    "        max_depth=depth,  # Maximum depth of trees\n",
    "        reg_lambda=l2_leaf_reg,  # L2 regularization strength (equivalent to CatBoost's l2_leaf_reg)\n",
    "        objective='multiclass',  # Multiclass classification\n",
    "        num_class=len(np.unique(label_train)),  # Number of classes\n",
    "        verbose=-1,\n",
    "        num_leaves=64,\n",
    "        num_threads=12\n",
    "    )\n",
    "    model.fit(feature_train, label_train)\n",
    "    y_pred = model.predict(feature_test)\n",
    "    accuracy_cat = accuracy_score(label_test, y_pred)\n",
    "    results[key] = accuracy_cat\n",
    "\n",
    "\n",
    "with_or_without_scaled_features = [True,\n",
    "                                    # False\n",
    "                                    ]\n",
    "feature_sets = [[ \"xDir\", \"yDir\", \"fixDensPerBB\"], \n",
    "                # [\"meanFix\", \"maxFix\", \"varFix\"], \n",
    "                # [\"meanFix\", \"maxFix\", \"varFix\", \"xDir\", \"yDir\"], \n",
    "                # [\"meanFix\", \"maxFix\", \"varFix\", \"xDir\", \"yDir\", \"fixDensPerBB\"],\n",
    "                # [\"meanFix\", \"maxFix\", \"varFix\", \"xDir\", \"yDir\", \"fixDensPerBB\"],\n",
    "                # [ 'blinkMean', 'blinkMin', 'blinkMax', 'blinkRate', 'xDir', 'yDir', 'fixDensPerBB', 'duration', 'participant_id'],\n",
    "                # [ 'varFix', 'stdFix', 'meanDis',  'varDis', 'stdDisp', 'freqDisPerSec', 'number_of_blinks', 'blinkMean', 'blinkRate', 'xDir', 'yDir', 'fixDensPerBB'],\n",
    "                # ['minFix', 'maxFix', 'minDis', 'maxDis', 'blinkMin', 'blinkMax', 'xDir', 'yDir', 'fixDensPerBB'],\n",
    "                # ['minFix', 'maxFix', 'varFix', 'stdFix', 'meanDis', 'minDis', 'maxDis', 'varDis', 'stdDisp', 'freqDisPerSec', 'number_of_blinks', 'blinkMean', 'blinkMin', 'blinkMax', 'blinkRate', 'xDir', 'yDir', 'fixDensPerBB', 'duration', 'participant_id']\n",
    "                ]\n",
    "results = {}\n",
    "iteration_list = [10, 100, 1000, 10000]\n",
    "learning_rate_list = [0.0005, 0.005, 0.05, 0.5]\n",
    "depth_list = [-1]\n",
    "l2_leaf_reg_list = [1, 2,3]\n",
    "\n",
    "for boo in with_or_without_scaled_features:\n",
    "    for f_set in feature_sets:\n",
    "        for i in iteration_list:\n",
    "            for l in learning_rate_list:\n",
    "                for d in depth_list:\n",
    "                    for l2 in l2_leaf_reg_list:\n",
    "                        feature_train, feature_test, label_train, label_test = setup_with_features(boo, f_set)\n",
    "                        test_parameters(results, boo, f_set, feature_train, feature_test, label_train, label_test, iterations=i, learning_rate=l, depth=d, l2_leaf_reg=l2)\n",
    "        print(\"Done with feature set: \" + str(f_set))\n",
    "    print(\"Done with scaling: \" + str(boo))\n",
    "\n",
    "print(results)\n",
    "\n",
    "# Specify the file path where you want to save the dictionary\n",
    "file_path = 'results.pkl'\n",
    "\n",
    "# Open the file in binary write mode ('wb')\n",
    "with open(file_path, 'wb') as file:\n",
    "    # Use pickle.dump to save the dictionary to the file\n",
    "    pickle.dump(results, file)\n",
    "\n",
    "sorted_dict = dict(sorted(results.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Print the top 3 key-value pairs\n",
    "top_3 = list(sorted_dict.items())[:3]\n",
    "for key, value in top_3:\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29ff2ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt',\n",
    "    n_iterations=10,  # Number of boostinstr(l2_leaf_reg)g iterations\n",
    "    learning_rate=0.005,  # Learning rate\n",
    "    max_depth=-1,  # Maximum depth of trees\n",
    "    reg_lambda=3,  # L2 regularization strength (equivalent to CatBoost's l2_leaf_reg)\n",
    "    objective='multiclass',  # Multiclass classification\n",
    "    num_class=len(np.unique(label_train)),  # Number of classes\n",
    "    verbose=-1,\n",
    "    num_leaves=64,\n",
    "    num_threads=12\n",
    ")\n",
    "\n",
    "model.fit(feature_train, label_train)\n",
    "\n",
    "with open('classifier.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "fcdc3df7d9ff602e58f242e0b8f38f02f517a6650d93a006332d70894316f3dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
